{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HRFlow - Profile API.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xfCgCDo-NBgb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfCgCDo-NBgb",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 HrFlow's AI Research Department\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8GMhizxO-OW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2020 HrFlow's AI Research Department. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaigUXB305hf",
        "colab_type": "text"
      },
      "source": [
        "# Profile API:\n",
        "\n",
        "This notebook illustrates how to use **HrFlow's Profile API**. This API serves as an interface to upload resumes (either structured as a json or as a file located in your hard drive) and retrieve results from HrFlow. In the current version, the following results can be retrieved or used:\n",
        "* The **Profile object** \n",
        "* The **Parsing object** \n",
        "* Any **attachments** that have been sent in an upload\n",
        "* The **search engine** over your source of profiles\n",
        "* The **scores** Score your profiles for a given job\n",
        "* The **embeddings** at various degree of granularity\n",
        "\n",
        "An **example of applications** with the Profile API is available below. The example shows how **embeddings** can be leveraged to **classify resumes**. \n",
        "\n",
        "**Embeddings** eases the management of documents like resumes of jobs. It turns any highly structured image of a resume into a single **vector of numbers** with fixed length. \n",
        "\n",
        "The document embeddings can also be trivially used to compute **job or profile level meaning similarity** as well as to enable better performance on downstream classification tasks using **less supervised training data**.\n",
        "\n",
        "**Disclaimer**: \n",
        "\n",
        "\n",
        "*   HR Resumes comes from google query '[cv hr](https://www.google.fr/search?q=cv+hr)'\n",
        "*   Data Scientists Resumes comes from Google query '[cv data scientist](https://www.google.fr/search?q=cv+data+scientist)'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCOyeBORIMLw",
        "colab_type": "text"
      },
      "source": [
        "<p>\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/Riminder/python-hrflow-api/blob/master/examples/colab/hrflow_profile_api.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/Riminder/python-hrflow-api/blob/master/examples/colab/hrflow_profile_api.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://www.hrflow.ai/book-us\">\n",
        "    <img width=32px src=\"https://gblobscdn.gitbook.com/spaces%2F-M1L6Hspq8r9LXd5_gIC%2Favatar-1586188377926.png?generation=1586188378327930&alt=media\" />Get an account</a>\n",
        "</td></table>\n",
        "<br>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEXb1qtd1AGL",
        "colab_type": "text"
      },
      "source": [
        "# Getting Started\n",
        "This section sets up the environment to get access to **HrFlow Profile API** and sets up a connection to HrFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASyCd5Ws08gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Machine Learning and Classification Libs\n",
        "!pip install --quiet tensorflow\n",
        "!pip install --quiet matplotlib\n",
        "!pip install --quiet pandas\n",
        "!pip install --quiet seaborn\n",
        "!pip install --quiet plotly\n",
        "\n",
        "# HrFlow Dependencies\n",
        "!apt-get install libmagic-dev\n",
        "!pip install --quiet python-magic\n",
        "!pip install --quiet hrflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLSSuHDiVMkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "ROOT_PATH = \"drive/My Drive/Data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84RDzqmzMDZF",
        "colab_type": "text"
      },
      "source": [
        "An **API Key** is required here. You can get your API Key at **https://```<your-sub domain/>```.hrflow.ai/settings/api/keys** or ask us for a **demo API Key**.\n",
        "\n",
        "Either add your API Key as a file in your 'ROOT_PATH' or set the python variable named api_secret to your  API Key (api_secret = 'YOUR_SECRET_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZlf9s621ubg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pprint\n",
        "import hrflow as hf\n",
        "\n",
        "with open(os.path.join(ROOT_PATH,'api_key'), 'rb') as file:\n",
        "  api_secret = pickle.load(file)\n",
        "\n",
        "client = hf.Client(api_secret=\"api_secret\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD_ELnYX1w4T",
        "colab_type": "text"
      },
      "source": [
        "# 1. Profile API Routes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h6_8lpyP8c7",
        "colab_type": "text"
      },
      "source": [
        "Routes of this API can be sub-divided into three categories:\n",
        "*  **Parsing**: Parsing profiles either as a file (picture: png, jpg, etc or document files: pdf, word, etc)\n",
        "*  **Indexing**: Indexing json profiles\n",
        "*  **Download**: Downloading profile object or indexing object or any attachments related to a profile\n",
        "*  **Advanced Tools**: Performing **Searches** throughout sources, computing **Scores** between profiles of one or many sources for a given job position, retrieve your profiles **Embeddings** to build your custom solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kADftEuE15D6",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Indexing Profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OdYCv7G7XNd",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1. Upload Profile JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDNGKeG6MjTZ",
        "colab_type": "text"
      },
      "source": [
        "client.profile.indexing.add_json takes two compulsory arguments:\n",
        "\n",
        "\n",
        "*   A **source key**: A source (of profiles) can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*   A python dictionary **profile_json**: The profile to be added to the source. This input is shaped as a dictionary '{key:value}' pairs. \n",
        "\n",
        "Currently, **profile_key** can only be retrieved through a webhook. \n",
        "\n",
        "Alternatively **profile_reference** or **profile_email** can be used instead of  **profile_key** to perform some tasks. However, only the creation of the **profile_key guarantees the processing** of your profile (parsing, revealing, embedding, etc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJrSWMB81zdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = {\n",
        "  \"consent_algorithmic\": {\n",
        "            \"owner\": {\n",
        "                \"parsing\": True,\n",
        "                \"revealing\": False,\n",
        "                \"embedding\": True,\n",
        "                \"searching\": False,\n",
        "                \"scoring\": True,\n",
        "                \"reasoning\": False\n",
        "            },\n",
        "            \"controller\": {\n",
        "                \"parsing\": True,\n",
        "                \"revealing\": False,\n",
        "                \"embedding\": True,\n",
        "                \"searching\": False,\n",
        "                \"scoring\": True,\n",
        "                \"reasoning\": False\n",
        "            }\n",
        "        },\n",
        "  \"info\" : {\n",
        "      \"full_name\":\"Harry Potter\",\n",
        "      \"first_name\": \"Harry\",\n",
        "      \"last_name\": \"Potter\",\n",
        "      \"email\":\"harry.potter@gmail.com\",\n",
        "      \"phone\":\"0202\",\n",
        "      \"gender\": None,\n",
        "      \"urls\": {\n",
        "          \"from_resume\": [],\n",
        "          \"linkedin\":\"\",\n",
        "          \"twitter\":\"\",\n",
        "          \"facebook\":\"\",\n",
        "          \"github\":\"\",\n",
        "          \"picture\":\"\"},\n",
        "      \"picture\":None,\n",
        "  \t  \"location\":{\"text\": None},\n",
        "  \t  \"summary\": \"Brief summary\"\n",
        "  },\n",
        "  \"experiences\": [{\n",
        "      \"date_start\":  {\"iso8601\": \"2018-01-01T00:00:00\"},\n",
        "      \"date_end\": {\"iso8601\": \"2018-07-01T00:00:00\"},\n",
        "      \"title\": \"Lead\",\n",
        "      \"company\": \"Mathematic Departement\",\n",
        "      \"location\": {\"text\":\"Paris\"},\n",
        "      \"description\": \"Developping.\"\n",
        "      }],\n",
        "  \"experiences_duration\":5,\n",
        "  \"educations\": [{\n",
        "      \"date_start\": {\"iso8601\": \"2016-01-01T00:00:00\"},\n",
        "      \"date_end\": {\"iso8601\": \"2018-01-01T00:00:00\"},\n",
        "      \"title\": \"Mathematicien\",\n",
        "      \"school\": \"University\",\n",
        "      \"description\": \"Description\",\n",
        "      \"location\": {\"text\":\"Scotland\", \"lat\":\"lat\", \"lng\": \"lng\"}\n",
        "  }],\n",
        "  \"educations_duration\":4,\n",
        "  \"skills\": [{\"name\":\"manual skill\", \"type\": \"hard\", \"value\": None},\n",
        "               {\"name\":\"Creative spirit\", \"type\": \"soft\",\"value\": None}, \n",
        "               {\"name\":\"Writing skills\", \"type\": \"hard\",\"value\": None}, \n",
        "               {\"name\":\"Communication\", \"type\": \"soft\",\"value\": None}],\n",
        "  \"languages\" : [{\"name\":\"english\", \"value\": None}],\n",
        "  \"interests\": [{\"name\":\"football\", \"value\": None}],\n",
        "  \"tags\":[{\"name\":\"archive\", \"value\": False}],\n",
        "  \"metadatas\":[],\n",
        "  \"labels\":[{\"stage\":\"yes\", \"job_key\":\"job_key\"}],\n",
        "  \"attachments\": []\n",
        "};\n",
        "\n",
        "response = client.profile.indexing.add_json(source_key=\"source_key\", profile_json=data)\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq6I1scdAG05",
        "colab_type": "text"
      },
      "source": [
        "###  1.1.2. Edit Profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9wv2nvrA8oC",
        "colab_type": "text"
      },
      "source": [
        "client.profile.indexing.edit takes three compulsory arguments:\n",
        "\n",
        "*   A **source key**: A source (of profiles) can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*   A **profile key**: A profile key that will be edited.\n",
        "*   A python dictionary **profile_json**: The profile to be edited to the source. This input is shaped as a dictionary '{key:value}' pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btTM77mOAR5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = {\n",
        "  \"consent_algorithmic\": {\n",
        "            \"owner\": {\n",
        "                \"parsing\": True,\n",
        "                \"revealing\": False,\n",
        "                \"embedding\": True,\n",
        "                \"searching\": False,\n",
        "                \"scoring\": True,\n",
        "                \"reasoning\": False\n",
        "            },\n",
        "            \"controller\": {\n",
        "                \"parsing\": True,\n",
        "                \"revealing\": False,\n",
        "                \"embedding\": True,\n",
        "                \"searching\": False,\n",
        "                \"scoring\": True,\n",
        "                \"reasoning\": False\n",
        "            }\n",
        "        },\n",
        "  \"info\" : {\n",
        "      \"full_name\":\"Harry Potter\",\n",
        "      \"first_name\": \"Harry\",\n",
        "      \"last_name\": \"Potter\",\n",
        "      \"email\":\"harry.potter@gmail.com\",\n",
        "      \"phone\":\"0202\",\n",
        "      \"gender\": None,\n",
        "      \"urls\": {\n",
        "          \"from_resume\": [],\n",
        "          \"linkedin\":\"\",\n",
        "          \"twitter\":\"\",\n",
        "          \"facebook\":\"\",\n",
        "          \"github\":\"\",\n",
        "          \"picture\":\"\"},\n",
        "      \"picture\":None,\n",
        "  \t  \"location\":{\"text\": None},\n",
        "  \t  \"summary\": \"Brief summary\"\n",
        "  },\n",
        "  \"experiences\": [{\n",
        "      \"date_start\":  {\"iso8601\": \"2018-01-01T00:00:00\"},\n",
        "      \"date_end\": {\"iso8601\": \"2018-07-01T00:00:00\"},\n",
        "      \"title\": \"Lead\",\n",
        "      \"company\": \"Mathematic Departement\",\n",
        "      \"location\": {\"text\":\"Paris\"},\n",
        "      \"description\": \"Developping.\"\n",
        "      }],\n",
        "  \"experiences_duration\":5,\n",
        "  \"educations\": [{\n",
        "      \"date_start\": {\"iso8601\": \"2016-01-01T00:00:00\"},\n",
        "      \"date_end\": {\"iso8601\": \"2018-01-01T00:00:00\"},\n",
        "      \"title\": \"Mathematicien\",\n",
        "      \"school\": \"University\",\n",
        "      \"description\": \"Description\",\n",
        "      \"location\": {\"text\":\"Scotland\", \"lat\":\"lat\", \"lng\": \"lng\"}\n",
        "  }],\n",
        "  \"educations_duration\":4,\n",
        "  \"skills\": [{\"name\":\"manual skill\", \"type\": \"hard\", \"value\": None},\n",
        "               {\"name\":\"Creative spirit\", \"type\": \"soft\",\"value\": None}, \n",
        "               {\"name\":\"Writing skills\", \"type\": \"hard\",\"value\": None}, \n",
        "               {\"name\":\"Communication\", \"type\": \"soft\",\"value\": None}],\n",
        "  \"languages\" : [{\"name\":\"english\", \"value\": None}],\n",
        "  \"interests\": [{\"name\":\"football\", \"value\": None}],\n",
        "  \"tags\":[{\"name\":\"archive\", \"value\": True}],\n",
        "  \"metadatas\":[],\n",
        "  \"labels\":[{\"stage\":\"yes\", \"job_key\":\"job_key\"}],\n",
        "  \"attachments\": []\n",
        "};\n",
        "\n",
        "response = client.profile.indexing.edit(source_key=\"source_key\", key=\"profile_key\", profile_json=data)\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho_h9EDpB0Al",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Parsing Profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfQgXYb2C3bj",
        "colab_type": "text"
      },
      "source": [
        "client.profile.parsing.add_file takes two compulsory arguments:\n",
        "\n",
        "\n",
        "*   A **source key**: A source (of profiles) can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*   **profile_file**: loaded binary file from disk using file object's read method\n",
        "*   **profile_content_type**: (.ie application/pdf...)\n",
        "* (Optional) **reference**: A string reference that can be used to access your uploaded profile's features\n",
        "*   **labels**: profile's labels\n",
        "                                [{\n",
        "                                  \"job_key\": \"job_key\",\n",
        "                                  \"job_reference\": \"test\",\n",
        "                                  \"stage\": \"yes\",\n",
        "                                  \"stage_timestamp\":1585662186,\n",
        "                                  \"rating\":0.5,\n",
        "                                  \"stage_timestamp\":1585662186\n",
        "                                }]\n",
        "*   **tags**: profile's tags \n",
        "                            [{\n",
        "                              \"name\":\"blacklist\",\"value\":true\n",
        "                              }]\n",
        "*   **metadatas**: profile's metadats \n",
        "                                    [{\n",
        "                                      \"name\":\"mail\",\"value\":\"test@test.com\"\n",
        "                                      }]\n",
        "*  **created_at**: Creation date as iso Format\n",
        "*  (optional) **sync_parsing**: either use fast parsing (set value to 1) or not (set value to 0 or ignore it). Default behavior uses asynchronous parsing.\n",
        "*  (Optional) **sync_parsing_indexing**: whether to index or not posted profile.\n",
        "Default behavior index all profiles.\n",
        "*  (Optional) **webhook_parsing_sending**: Receive or not webhook notification after indexing success or update. Default behavior is not to send success/update notification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8HnHcr_CK1d",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1. Async Parsing Profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMnArx2BGQma",
        "colab_type": "text"
      },
      "source": [
        " **sync_parsing** = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXYuYySgGfXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(ROOT_PATH+'/fake_resumes/original.pdf',\"rb\") as file:\n",
        "    profile_file = file.read()\n",
        "    \n",
        "response = client.profile.parsing.add_file(source_key=\"source_key\",  profile_file=profile_file, profile_content_type='application/pdf', reference='profile_reference',\n",
        "                        labels=[\n",
        "                          {\n",
        "                            \"job_key\": \"job_key\",\n",
        "                            \"job_reference\": \"test\",\n",
        "                            \"stage\": \"yes\",\n",
        "                            \"stage_timestamp\":1585662186,\n",
        "                            \"rating\":0.5,\n",
        "                            \"stage_timestamp\":1585662186\n",
        "                          }, \n",
        "                        ],\n",
        "                        tags=[{\"name\":\"blacklist\",\"value\":true}], metadatas=[{\"name\":\"mail\",\"value\":\"test@test.com\"}], created_at: \"2016-01-01T00:00:00\",\n",
        "                        sync_parsing=0, sync_parsing_indexing=1, webhook_parsing_sending=0)\n",
        "\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plC2nGHEIeJc",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2. Sync Parsing Profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ1OCCevIpkZ",
        "colab_type": "text"
      },
      "source": [
        " **sync_parsing** = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpwaeUXXIuYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(ROOT_PATH+'/fake_resumes/original.pdf',\"rb\") as file:\n",
        "    profile_file = file.read()\n",
        "    \n",
        "response = client.profile.parsing.add_file(source_key=\"source_key\",  profile_file=profile_file, profile_content_type='application/pdf', reference='profile_reference',\n",
        "                        labels=[\n",
        "                          {\n",
        "                            \"job_key\": \"job_key\",\n",
        "                            \"job_reference\": \"test\",\n",
        "                            \"stage\": \"yes\",\n",
        "                            \"stage_timestamp\":1585662186,\n",
        "                            \"rating\":0.5,\n",
        "                            \"stage_timestamp\":1585662186\n",
        "                          }, \n",
        "                        ],\n",
        "                        tags=[{\"name\":\"blacklist\",\"value\":true}], metadatas=[{\"name\":\"mail\",\"value\":\"test@test.com\"}], created_at: \"2016-01-01T00:00:00\",\n",
        "                        sync_parsing=1, sync_parsing_indexing=1, webhook_parsing_sending=0)\n",
        "\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBoGaCn5RrqV",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ETGYWqT7zlj",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.1 Profile's Attachment Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_QadKLBUmPs",
        "colab_type": "text"
      },
      "source": [
        "client.profile.attachment.list two mandatory fields:\n",
        "*   **source key**: A source can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*  **key**: Retrievable through a webhook after an uploaded has been made. Alternatively, **reference** or **email** can be used if it has been set while uploading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ObzY2999Uy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response =  client.profile.attachment.list(source_key=\"source_key\", key=\"profile_key\")\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MqISquNBAll-"
      },
      "source": [
        "### 1.3.2 Profile object Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDwi70BiA1KS"
      },
      "source": [
        "client.profile.indexing.get two mandatory fields:\n",
        "*   **source key**: A source can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*  **key**: Retrievable through a webhook after an uploaded has been made. Alternatively, **reference** or **email** can be used if it has been set while uploading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kRzRbNjaBDnO",
        "colab": {}
      },
      "source": [
        "response = client.profile.indexing.get(source_key=\"source_key\", key=\"profile_key\")\n",
        "\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJidwnTy7-W4",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.3. Get Parsing object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lne4hiVhVltV",
        "colab_type": "text"
      },
      "source": [
        "client.profile.parsing.get two mandatory fields:\n",
        "*   **source key**: A source can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*  **key**: Retrievable through a webhook after an uploaded has been made. Alternatively, **reference** or **email** can be used if it has been set while uploading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebvx1W359HLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.parsing.get(source_key=\"source_key\", key=\"profile_key\")\n",
        "\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCPdvf01R1HB",
        "colab_type": "text"
      },
      "source": [
        "## 1.4. Advanced Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8gdlPAT8LjH",
        "colab_type": "text"
      },
      "source": [
        "### 1.4.1 Profile Search Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOy4-hQpedFk",
        "colab_type": "text"
      },
      "source": [
        "client.profile.searching searches profiles from **source_keys** (python list of source_key) which follows a set of filtering fields (creted_at_min: date as iso; include/exclude tags ...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PESi3ZDY88UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response =  client.profile.searching.list(source_keys=[\"source_key\"], page=1, limit=30, sort_by='created_at', order_by=\"desc\",\n",
        "                                          created_at_min='2020-07-09T13:35:11+0000', tags_included = [[{'name': 'blacklist', 'value': False}]])\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W9H4fU98Uhr",
        "colab_type": "text"
      },
      "source": [
        "### 1.4.2 Profile's Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUSWPNuogq93",
        "colab_type": "text"
      },
      "source": [
        "client.profile.scoring scores profiles from **source_keys** (python list of source_key) with regards to a **job_key**. job_key can be retrieved using the **Job API** or by creating a new job at **https://```<your-sub domain/>```.hrflow.ai/marketplace/agents**. The underlying **scoring agent** (classifier model) is linked to the job_key while creating the job."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O29UHZkl8yPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.scoring.list(source_keys=[\"source_key\"],\n",
        "                                  board_key=\"board_key\",\n",
        "                                  job_key=\"job_key\",\n",
        "                                  use_agent=1, stage='new',\n",
        "                                  page=1, limit=30, sort_by='created_at', order_by=None, \n",
        "                                  text_keywords=['python'],\n",
        "                                  tags_excluded = [[{'name': 'blacklist', 'value': False}]])\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W53-fyTZ8ejo",
        "colab_type": "text"
      },
      "source": [
        "### 1.4.3 Embeddings Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iI996DZhw-8",
        "colab_type": "text"
      },
      "source": [
        "client.profile.embedding.get returns embeddings for a given profile (uniquely defined by the pair **source_key** and **profile_key**). HrFlow provides multiple level of embedding **granularity**. You can either retrieve the overall profile embedding, the embedding associated to the n-th experiences or any other **fields**. The wanted embeddings for a profile needs to be specified through the 'fields' input variable.\n",
        "\n",
        "This methods presently handles only profile per profile embeddings. A loop is required to get embeddings for more than one profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsQzspgF8mGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.embedding.get(source_key='source_key',\n",
        "                                        key='profile_key',\n",
        "                                        fields={'profile': 1, 'skills':1, 'educations':[0]})\n",
        "pprint.pprint(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZRVEXT514MU",
        "colab_type": "text"
      },
      "source": [
        "# 2. Application Example: Machine Learning With Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4EMaLWrjR1O",
        "colab_type": "text"
      },
      "source": [
        "Embeddings is widely used these last years (2013 onwards) in the field of *Natural Language Processing*, thanks to Tomas Mikolov and his team at Google. Their breakthrough on building reliable embeddings for words had a huge impact both scientifically and technologically.\n",
        "\n",
        "The rough idea behind embeddings consists in **numerically capture the meaning or informations** of a word (or sentence or even a whole document like a resume). Any resume can thus be relatively accurately represented by a set of real numbers ('vector of floats'). The **measure of accuracy** is evaluated to a predefined task. \n",
        "\n",
        "An embedding algorithm is deemed to be 'good' as for being good for a given **evaluation task**. In the case of word embeddings, the latter can be trained and evaluated (on the same task) on filling sentences gaps. This task quantifies how an embedding algorithm performs at knowing a sentence context (sequence words in the sentence) by filling missing words.\n",
        "\n",
        "In our case, the most obvious, practical and meaningfull evaluation task is the **classification of resumes** (which ones are 'bakers', 'data scientists', etc or which ones are better than others, etc). This task is usually quite easily done by humans (Human Resources departments) and relatively well done by computers (keywords).\n",
        "\n",
        "The following cells of this notebook shows a relatively simple model that classifies 'Data Scientists' against 'Human Resources' based on fake resumes (found on google, check disclaimer above). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6i4EvEMYrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_embedding(url):\n",
        "  response = requests.get(url, stream=True)\n",
        "  with open('tmp', 'wb') as file:\n",
        "      shutil.copyfileobj(response.raw, file)\n",
        "  return np.load('tmp', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuNyJlGEBlel",
        "colab_type": "text"
      },
      "source": [
        "## 2.0. Embeddings Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nYSV4k0zdgi",
        "colab_type": "text"
      },
      "source": [
        "A set of data scientists resumes has been uploaded using client.profile.add_file method. In this section we are retrieving (requires **source_key** and a list of **profile_key**) our uploaded profiles products (parsing and embedding). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGMBp3i-19MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_key = 'b18eacf7c984c677af6fd0b1fdaaff710b6fa065'\n",
        "\n",
        "data_scientist_keys = ['8f1c04ddb3aa1c00b1b0f406724cf7d260cddaa1', 'b4ec818197ef22f39c9a3761661847981eeb7d43', 'b96a60419769594e6ea4df36cebdb78d3800ce6d', \n",
        "                      '6aabceebb833d97257b6beb1335414536b873651', 'f01119ebe76dd3a979fe309f12d174ee3ec57f84', 'ade02d1f95673a126c96d0553f1daa3ae3c1cacc', \n",
        "                      '81aed5caa0331e96549136ea5cf90fdbf1bef2a5', '59adec3b482f41fdfb8d24a79069decfeb09d191', '2403d2584670a430d14bc45121be6edb9e46c0a6']\n",
        "hr_keys = ['4c2f88ed9ec17859176a9e6bfba765e108e1be9c', 'ea343d3843121bf760ee6afb40c73ce1fae80d21', '7bafcfd41d86814940593ba68658d3782380dc0c',\n",
        "          'fdde179cc1194a1ebdcb250cff590b6426801497', '9659dd9167c50bc401aea57987b65b91a7c2caa3', '9d36930fa252ed53a11a71110bb1998ea73249ba', \n",
        "          '2840d1c78e870d7905cc217945fb9963b703b51b']\n",
        "profiles_ids = data_scientist_keys + hr_keys\n",
        "job_types = ['data_scientist']*len(data_scientist_keys) + ['hr']*len(hr_keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6uAjnrKMGqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "job_types_labels = {'data_scientist': 0, 'hr': 1}\n",
        "profiles_embeddings = []\n",
        "labels = []\n",
        "profiles_json = []\n",
        "\n",
        "for job_type, profile_key in tqdm(zip(job_types, profiles_ids)):\n",
        "  # Retrieving Embeddings\n",
        "  response = client.profile.embedding.get(source_key=source_key, key=profile_key, fields={'profile': 1})\n",
        "  print(profile_key)\n",
        "  profiles_embeddings.append(load_embedding(response['data']['profile']))\n",
        "  labels.append(job_types_labels[job_type])\n",
        "  # Retrieving Parsed Profiles\n",
        "  response = client.profile.parsing.get(source_key=source_key, key=profile_key)\n",
        "  profiles_json.append(response['data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjbovF8cC_my",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Profile Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aA5R3ElDEic",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.a Model: Shallow Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hcnR8Hp0SQd",
        "colab_type": "text"
      },
      "source": [
        "Our Neural Network is a single (shallow) hidden layer network defined by three layers:\n",
        "*  Input: profiles embeddings lies into $R^{64}$. This explains the input shape 'shape=(64,)'\n",
        "*  Hidden Layer: a simple 64-neurons dense using tanh ($x\\mapsto (e^x-1)/(e^x+1)$) activation function\n",
        "*  Output: probabilities-like real numbers using softmax activation function.\n",
        "\n",
        "Since we are building a classifier we are compiling with the most common loss and optimizer (categorical crossentropy and Adam respectively). More informations about tensorflow neural network library can be found in https://www.tensorflow.org/api_docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbdO0MpQDDGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Model Definition\n",
        "model_input = Input(shape=(64,))\n",
        "dense = Dense(64, activation='tanh')(model_input)\n",
        "softmax = Dense(2, activation='softmax')(dense)\n",
        "model = Model(inputs=[model_input], outputs=[softmax])\n",
        "\n",
        "# Model Compilation (required for training)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZf00SSFDJPh",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.b. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwo25OeF6ThI",
        "colab_type": "text"
      },
      "source": [
        "Remarks on model.fit inputs:\n",
        "*  np.asarray: inputs are feeded as numpy arrays (we retrieved profiles embeddings as python list of arrays)\n",
        "*  to_categorical: the output of the model is a 'list' of (1-p, p) where p is the probability of being part of the second class (label 1). to_categorical turns labels into this shape.\n",
        "*  epochs: can be set to quite any desired value here (since this model does not have any production purpose). 10 epochs (or passes through the data set) proved to be enough for this model to reach good results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n97CmKV7DND5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x=np.asarray(profiles_embeddings), \n",
        "          y=to_categorical(np.asarray(labels)),\n",
        "          epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JesH9mGkDD1u",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.c. Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISlHg-s5kRZU",
        "colab_type": "text"
      },
      "source": [
        "Due to the lack of resumes, the model is evaluated on its training own data (instead of on a validation set). Two evaluation methods are shown:\n",
        "\n",
        "\n",
        "1.   **Confusion Matrix**: a matrix that shows the number of:\n",
        "*   On the **diagonal**: **rightfully predicted** classes\n",
        "*   Anywhere else: wrongly classified resumes\n",
        "\n",
        "\n",
        "2.   **Principal Component Analysis Plot**: uses dimension reduction (projection towards high variance axes) to show high dimensional vectors into a lower dimension (usually 2 or 3). **Decision boundaries** are plotted using the model prediction over a mesh in embedding space. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zX8qMuXDQ1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "# Scatter Plot Hover Text Formating\n",
        "def line_jump(text, every_char=50):\n",
        "    n_jumps = len(text) // every_char\n",
        "    output = text[:every_char]\n",
        "    for index in range(1, n_jumps):\n",
        "        output += '<br />' + text[every_char*index:every_char*(index+1)] \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Imcz3uVDUPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Model's Predictions on Test Set\n",
        "predictions = np.argmax(model.predict(np.asarray(profiles_embeddings)), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27qUcYncDVbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confusion Matrix\n",
        "confusion_matrix = np.asarray(tf.math.confusion_matrix(labels, predictions))\n",
        "text = np.asarray([['Data Scientist detected\\n as Data Scientist', 'Data Scientist wrongly detected\\n as Human Resources'], \n",
        "                   ['Human Resources wrongly detected\\n as Data Scientist', 'Human Resources detected\\n as Human Resources']])\n",
        "text_conf_mat = (np.asarray([\"{1:g}\\n{0}\".format(txt, value) for txt, value in zip(text.flatten(), confusion_matrix.flatten())])).reshape(2,2)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "fig, ax = plt.subplots(figsize=(10,10)) \n",
        "sns.heatmap(confusion_matrix, \n",
        "            linewidths=0.5, cmap=\"YlGnBu\", square=True, \n",
        "            xticklabels=['Data Scientist', 'HR'], yticklabels=['Data Scientist', 'HR'],\n",
        "            annot=text_conf_mat, annot_kws={\"size\": 12}, fmt=\"\")\n",
        "plt.xlabel('Predicted Label', fontsize=15)\n",
        "plt.ylabel('True Label', fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewc8HrF2DXQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jobs_list = list(job_types_labels.keys())\n",
        "\n",
        "# Principal Component Analysis in Dimension 2\n",
        "pca = PCA(n_components=2).fit(profiles_embeddings)\n",
        "pca_embeddings = pca.transform(profiles_embeddings)\n",
        "\n",
        "# DataFrame\n",
        "df = DataFrame({'Summary': [line_jump(profile['text']['en'][:500], every_char=50) for profile in profiles_json],\n",
        "                'Predicted Category': [jobs_list[pred] for pred in predictions],\n",
        "                'Category': ['Human Resources' if job=='hr' else 'Data Scientist' for job in job_types],\n",
        "                'Classification Success': [jobs_list[pred]==job for pred, job in zip(predictions, job_types)],\n",
        "                'First PCA Axis': pca_embeddings[:, 0], \n",
        "                'Second PCA Axis': pca_embeddings[:, 1]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDYOUAXuBAB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Compute Scores for Mesh Values\n",
        "h = 0.25\n",
        "x_min, x_max = -4, 4\n",
        "y_min, y_max = -4, 4\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "Xmesh = np.c_[xx.ravel(), yy.ravel()]\n",
        "mesh_values = model.predict(pca.inverse_transform(Xmesh))[:,1]\n",
        "\n",
        "# Contour/Boundary Plot\n",
        "data = go.Contour(z=mesh_values,\n",
        "                  x=np.arange(x_min, x_max, h), \n",
        "                  y=np.arange(y_min, y_max, h),\n",
        "                  colorscale=[[0.0, \"rgb(165,0,38)\"],\n",
        "                              [0.1111111111111111, \"rgb(215,48,39)\"],\n",
        "                              [0.2222222222222222, \"rgb(244,109,67)\"],\n",
        "                              [0.3333333333333333, \"rgb(253,174,97)\"],\n",
        "                              [0.4444444444444444, \"rgb(254,224,144)\"],\n",
        "                              [0.5555555555555556, \"rgb(224,243,248)\"],\n",
        "                              [0.6666666666666666, \"rgb(171,217,233)\"],\n",
        "                              [0.7777777777777778, \"rgb(116,173,209)\"],\n",
        "                              [0.8888888888888888, \"rgb(69,117,180)\"],\n",
        "                              [1.0, \"rgb(49,54,149)\"]])\n",
        "layout = {'width': 600, 'height': 600, 'showlegend': False, \n",
        "          'xaxis_title': 'First PCA Axis', \n",
        "          'yaxis_title': 'Second PCA Axis', 'title': 'PCA with Decision Boundaries (HR in red, Data Scientist in Blue)'}\n",
        "fig = go.Figure(data = data, layout=layout)\n",
        "\n",
        "# Profiles Embeddings + PCA 2D\n",
        "scatter = px.scatter(df, x='First PCA Axis', y='Second PCA Axis', \n",
        "                     hover_data=['Summary', 'Predicted Category', 'Category', 'Classification Success'],\n",
        "                     hover_name='Category',\n",
        "                     color='Predicted Category',\n",
        "                     color_discrete_sequence=[\"rgb(165,0,38)\", \"rgb(49,54,149)\"],\n",
        "                     symbol='Classification Success',\n",
        "                     symbol_map={True: \"circle\", False: \"square-open\"})\n",
        "scatter.update_traces(marker=dict(size=10, line=dict(width=1, color=\"rgb(230,230,230)\")))\n",
        "fig.add_trace(scatter.data[0])\n",
        "fig.add_trace(scatter.data[1])\n",
        "\n",
        "# Show Graph\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}