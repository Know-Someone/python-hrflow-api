{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HRFlow - Profile API.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xfCgCDo-NBgb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfCgCDo-NBgb",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 HRFlow's AI Research Department\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8GMhizxO-OW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2020 HRFlow's AI Research Department. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaigUXB305hf",
        "colab_type": "text"
      },
      "source": [
        "# Profile API:\n",
        "\n",
        "This notebook illustrates how to use **HRFlow's Profile API**. This API serves as an interface to upload resumes (either structured as a json or as a file located in your hard drive) and retrieve results from HRFlow. In the current version, the following results can be retrieved or used:\n",
        "* The **parsed resume** \n",
        "* Any **attachments** that have been sent in an upload\n",
        "* The **search engine** over your source of profiles\n",
        "* The **scores** between your profiles and a given job\n",
        "* The **embeddings** at various degree of granularity\n",
        "\n",
        "An **example of applications** with the Profile API is available below. The example shows how **embeddings** can be leveraged to **classify resumes**. \n",
        "\n",
        "**Embeddings** eases the management of documents like resumes of jobs. It turns any highly structured image of a resume into a single **vector of numbers** with fixed length. \n",
        "\n",
        "The document embeddings can also be trivially used to compute **job or profile level meaning similarity** as well as to enable better performance on downstream classification tasks using **less supervised training data**.\n",
        "\n",
        "**Disclaimer**: \n",
        "\n",
        "\n",
        "*   HR Resumes comes from google query '[cv hr](https://www.google.fr/search?q=cv+hr)'\n",
        "*   Data Scientists Resumes comes from Google query '[cv data scientist](https://www.google.fr/search?q=cv+data+scientist)'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCOyeBORIMLw",
        "colab_type": "text"
      },
      "source": [
        "<p>\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/Riminder/python-hrflow-api/blob/master/examples/colab/hrflow_profile_api.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/Riminder/python-hrflow-api/blob/master/examples/colab/hrflow_profile_api.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://www.hrflow.ai/book-us\">\n",
        "    <img width=32px src=\"https://gblobscdn.gitbook.com/spaces%2F-M1L6Hspq8r9LXd5_gIC%2Favatar-1586188377926.png?generation=1586188378327930&alt=media\" />Get an account</a>\n",
        "</td></table>\n",
        "<br>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEXb1qtd1AGL",
        "colab_type": "text"
      },
      "source": [
        "# Getting Started\n",
        "This section sets up the environment to get access to **HRFlow Profile API** and sets up a connection to HRFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASyCd5Ws08gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Machine Learning and Classification Libs\n",
        "!pip install --quiet tensorflow\n",
        "!pip install --quiet matplotlib\n",
        "!pip install --quiet pandas\n",
        "!pip install --quiet seaborn\n",
        "!pip install --quiet plotly\n",
        "\n",
        "# HRFlow Dependencies\n",
        "!apt-get install libmagic-dev\n",
        "!pip install --quiet python-magic\n",
        "!pip install --quiet hrflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLSSuHDiVMkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "ROOT_PATH = \"drive/My Drive/Data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84RDzqmzMDZF",
        "colab_type": "text"
      },
      "source": [
        "An **API Key** is required here. You can get your API Key at **https://```<your-sub domain/>```.hrflow.ai/settings/api/keys** or ask us for a **demo API Key**.\n",
        "\n",
        "Either add your API Key as a file in your 'ROOT_PATH' or set the python variable named api_secret to your  API Key (api_secret = 'YOUR_SECRET_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZlf9s621ubg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pprint\n",
        "import hrflow as hf\n",
        "\n",
        "with open(os.path.join(ROOT_PATH,'api_key'), 'rb') as file:\n",
        "  api_secret = pickle.load(file)\n",
        "\n",
        "client = hf.Client(api_secret=api_secret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD_ELnYX1w4T",
        "colab_type": "text"
      },
      "source": [
        "# 1. Profile API Routes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h6_8lpyP8c7",
        "colab_type": "text"
      },
      "source": [
        "Routes of this API can be sub-divided into three categories:\n",
        "*  **Upload**: Uploading profiles either as a file (picture: png, jpg, etc or document files: pdf, word, etc)\n",
        "*  **Download**: Downloading parsed resume or any attachments related to a profile\n",
        "*  **Advanced Tools**: Performing **Searches** throughout sources, computing **Scores** between profiles of one or many sources for a given job position, retrieve your profiles **Embeddings** to build your custom solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kADftEuE15D6",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Upload Profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OdYCv7G7XNd",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1. Upload JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDNGKeG6MjTZ",
        "colab_type": "text"
      },
      "source": [
        "client.profile.add_json takes two compulsory arguments:\n",
        "\n",
        "\n",
        "*   A **source id**: A source (of profiles) can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*   A python dictionary **profile_json**: The profile to be added to the source. This input is shaped as a dictionary '{key:value}' pairs. \n",
        "* (Optional) **profile_tags**: A list of tags that needs to be associated to the profile\n",
        "* (Optional) **profile_reference**: A string reference that can be used to access your uploaded profile's features\n",
        "\n",
        "Currently, **profile_id** can only be retrieved through a webhook. The **item_id** is only related to the upload and have no relationship with **profile_id**. \n",
        "\n",
        "Alternatively **profile_reference** can be used instead of  **profile_id** to perform some tasks. However, only the creation of the **profile_id guarantees the processing** of your profile (parsing, revealing, embedding, etc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJrSWMB81zdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "profile_json ={\n",
        "            \"name\": \"Hari Seldon\",\n",
        "            \"email\": \"harisledon@trantor.trt\",\n",
        "            \"address\": \"1 rue streeling\",\n",
        "            \"info\" : {\"name\":\"name info\", \"email\":\"tata\",\"phone\":\"0202\",\"location\":\"somewhere\",\"urls\": {\"from_resume\": [], \"linkedin\":\"\",\"twitter\":\"\",\"facebook\":\"\",\"github\":\"\",\"picture\":\"\"},\"location\":{\"text\":\"\"}},\n",
        "            \"summary\": \"test summary\",\n",
        "            \"experiences\": [\n",
        "              {\n",
        "                \"start\": \"15/02/12600\",\n",
        "                \"end\": \"\",\n",
        "                \"title\": \"Lead\",\n",
        "                \"company\": \"Departement de la psychohistoire\",\n",
        "                \"location\": {\"text\":\"Trator\"},\n",
        "                \"description\": \"Developping psychohistoire.\"\n",
        "              }\n",
        "            ],\n",
        "            \"educations\": [\n",
        "              {\n",
        "                \"start\": \"12540\",\n",
        "                \"end\": \"12550\",\n",
        "                \"title\": \"Diplome d'ingénieur mathematicien\",\n",
        "                \"school\": \"Université de Hélicon\",\n",
        "                \"description\": \"Etude des mathematique\",\n",
        "                \"location\": {\"text\":\"Hélicon\"}\n",
        "              }\n",
        "            ],\n",
        "            \"skills\": [\n",
        "              \"manual skill\",\n",
        "              \"Creative spirit\",\n",
        "              \"Writing skills\",\n",
        "              \"Communication\",\n",
        "              \"Project management\",\n",
        "              \"French\",\n",
        "              \"German\",\n",
        "              \"Korean\",\n",
        "              \"English\",\n",
        "              \"Esquive\",\n",
        "              \"Research\",\n",
        "              \"Mathematique\"\n",
        "            ],\n",
        "           \"languages\" : [\"arab\"],\n",
        "           \"interests\": [\"football\"],\n",
        "          \"tags\":[],\n",
        "          \"metadatas\":[],\n",
        "          \"labels\":[]\n",
        "          }\n",
        "response = client.profile.add_json(source_id=\"a62ae2d5560fca7b34bb6c0c389a378f99bcdd52\", \n",
        "                                   profile_json=profile_json,\n",
        "                                   profile_tags =[{\"name\": \"email\", \"value\":\"test@test.com\"}])\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZmQZONY7dkS",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.2. Upload Resume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVMqp-R0SusA",
        "colab_type": "text"
      },
      "source": [
        "client.profile.add_file takes two mandatory fields:\n",
        "*   **source id**: A source (of profiles) can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*  **profile_file**: loaded binary file from disk using file object's read method\n",
        "*  (optional) **sync_parsing**: either use fast parsing (set value to 1) or not (set value to 0 or ignore it). Default behavior uses asynchronous parsing.\n",
        "* (Optional) **profile_reference**: A string reference that can be used to access your uploaded profile's features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j06XjZy7iNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(ROOT_PATH+'/fake_resumes/original.pdf',\"rb\") as file:\n",
        "    profile_binary = file.read()\n",
        "response = client.profile.add_file(source_id=\"2be272f86ae21c311a4e0ee9401092026de063fc\",\n",
        "                                   sync_parsing=0,\n",
        "                                   profile_content_type='application/pdf',\n",
        "                                   profile_file=profile_binary,\n",
        "                                   profile_tags=[{\"name\" : \"email\", \"value\": \"test@hrflow.ai\"},\n",
        "                                                 {\"name\" : \"blacklist\", \"value\": True}])\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBoGaCn5RrqV",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ETGYWqT7zlj",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 Profile's Attachment Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_QadKLBUmPs",
        "colab_type": "text"
      },
      "source": [
        "client.profile.attachment.list two mandatory fields:\n",
        "*   **source id**: A source can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*  **profile_id**: Retrievable through a webhook after an uploaded has been made. Alternatively, **profile_reference** can be used if it has been set while uploading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ObzY2999Uy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.attachment.list(source_id=\"a62ae2d5560fca7b34bb6c0c389a378f99bcdd52\",\n",
        "                                          profile_id=\"597b16789ba389cbc67a638d808b8f40220ba988\")\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MqISquNBAll-"
      },
      "source": [
        "### 1.2.2 Profile's Tag Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDwi70BiA1KS"
      },
      "source": [
        "client.profile.tag.list two mandatory fields:\n",
        "*   **source id**: A source can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*  **profile_id**: Retrievable through a webhook after an uploaded has been made. Alternatively, **profile_reference** can be used if it has been set while uploading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kRzRbNjaBDnO",
        "colab": {}
      },
      "source": [
        "response = client.profile.tag.list(source_id=\"a62ae2d5560fca7b34bb6c0c389a378f99bcdd52\",\n",
        "                                          profile_id=\"597b16789ba389cbc67a638d808b8f40220ba988\")\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f0HCrQaYBZd9"
      },
      "source": [
        "### 1.2.3 Profile's Metadata Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a2hjwpUKBhT5"
      },
      "source": [
        "client.profile.metadata.list two mandatory fields:\n",
        "*   **source id**: A source can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*  **profile_id**: Retrievable through a webhook after an uploaded has been made. Alternatively, **profile_reference** can be used if it has been set while uploading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1zyERJGRBq45",
        "colab": {}
      },
      "source": [
        "response = client.profile.metadata.list(source_id=\"a62ae2d5560fca7b34bb6c0c389a378f99bcdd52\",\n",
        "                                          profile_id=\"597b16789ba389cbc67a638d808b8f40220ba988\")\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJidwnTy7-W4",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.4 Get Parsed Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lne4hiVhVltV",
        "colab_type": "text"
      },
      "source": [
        "client.profile.parsing.get two mandatory fields:\n",
        "*   **source id**: A source can be created or accessed at **https://```<your-sub domain/>```.hrflow.ai/sources**. It corresponds to a source of profiles.\n",
        "*  **profile_id**: Retrievable through a webhook after an uploaded has been made. Alternatively, **profile_reference** can be used if it has been set during the upload."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebvx1W359HLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.parsing.get(source_id=\"a62ae2d5560fca7b34bb6c0c389a378f99bcdd52\",\n",
        "                                      profile_id=\"597b16789ba389cbc67a638d808b8f40220ba988\")\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCPdvf01R1HB",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. Advanced Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8gdlPAT8LjH",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.1 Profile Search Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOy4-hQpedFk",
        "colab_type": "text"
      },
      "source": [
        "client.profile.searching searches profiles from **source_ids** (python list of source_id) which follows a set of filtering fields (seniority; stage: \"yes\", \"no\" or \"new\"; date_start: timestamp as string; date_end)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PESi3ZDY88UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.searching.get(source_ids=[\"a62ae2d5560fca7b34bb6c0c389a378f99bcdd52\"], stage=\"new\", date_start=\"1494539999\", limit=1)\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W9H4fU98Uhr",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.2 Profile's Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUSWPNuogq93",
        "colab_type": "text"
      },
      "source": [
        "client.profile.scoring.search scores profiles from **source_ids** (python list of source_id) with regards to a **job_id**. job_id can retrieved using the **Job API** or by creating a new job at **https://```<your-sub domain/>```.hrflow.ai/marketplace/agents**. The underlying **scoring agent** (classifier model) is linked to the job_id while creating the job."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O29UHZkl8yPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.scoring.get(source_ids=[\"a62ae2d5560fca7b34bb6c0c389a378f99bcdd52\"],\n",
        "                                         job_id=\"a25bc879e774cc508706f6f4ddd8cce036689f3a\",\n",
        "                                         stage=\"yes\")\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W53-fyTZ8ejo",
        "colab_type": "text"
      },
      "source": [
        "### 1.3.3 Embeddings Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iI996DZhw-8",
        "colab_type": "text"
      },
      "source": [
        "client.profile.embedding.get returns embeddings for a given profile (uniquely defined by the pair **source_id** and **profile_id**). HRFlow provides multiple level of embedding **granularity**. You can either retrieve the overall profile embedding, the embedding associated to the n-th experiences or any other **fields**. The wanted embeddings for a profile needs to be specified through the 'fields' input variable.\n",
        "\n",
        "This methods presently handles only profile per profile embeddings. A loop is required to get embeddings for more than one profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsQzspgF8mGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.embedding.get(source_id='a62ae2d5560fca7b34bb6c0c389a378f99bcdd52',\n",
        "                                        profile_id='597b16789ba389cbc67a638d808b8f40220ba988',\n",
        "                                        fields={'profile': 1, 'skills':1, 'educations':[0]})\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xp41Gy4KKZTp"
      },
      "source": [
        "### 1.3.4 Upload by Batch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnrdBTaCMbHD",
        "colab_type": "text"
      },
      "source": [
        "Upload by batch to HRFlow's platform. The resumes are selected using the paths argument and can be a directory or just a file. In case a profile does not get sent, a folder named failed-resumes will be created in the current directory with a copy of the failed files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUUho0aXMc7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.importer.upload(source_id=\"6bad4d9d79366fa71a747df48194617f3e483a9e\",\n",
        "                                          target=[ROOT_PATH+'/fake_resumes/'])\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HMYofSprL9ty"
      },
      "source": [
        "### 1.3.5 Download by Batch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSt5aypUM57N",
        "colab_type": "text"
      },
      "source": [
        "Download profile's documents of candidates and profile parsing from the sources that you selected. These documents are dump in the target directory you selected under the following path: taget_path/source_name_source_id/profile_id/*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V_-e1VONG_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = client.profile.exporter.download(source_ids=['2be272f86ae21c311a4e0ee9401092026de063fc'],\n",
        "                                            target=ROOT_PATH+'/fake_resumes/')\n",
        "pprint.pprint(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZRVEXT514MU",
        "colab_type": "text"
      },
      "source": [
        "# 2. Application Example: Machine Learning With Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4EMaLWrjR1O",
        "colab_type": "text"
      },
      "source": [
        "Embeddings is widely used these last years (2013 onwards) in the field of *Natural Language Processing*, thanks to Tomas Mikolov and his team at Google. Their breakthrough on building reliable embeddings for words had a huge impact both scientifically and technologically.\n",
        "\n",
        "The rough idea behind embeddings consists in **numerically capture the meaning or informations** of a word (or sentence or even a whole document like a resume). Any resume can thus be relatively accurately represented by a set of real numbers ('vector of floats'). The **measure of accuracy** is evaluated to a predefined task. \n",
        "\n",
        "An embedding algorithm is deemed to be 'good' as for being good for a given **evaluation task**. In the case of word embeddings, the latter can be trained and evaluated (on the same task) on filling sentences gaps. This task quantifies how an embedding algorithm performs at knowing a sentence context (sequence words in the sentence) by filling missing words.\n",
        "\n",
        "In our case, the most obvious, practical and meaningfull evaluation task is the **classification of resumes** (which ones are 'bakers', 'data scientists', etc or which ones are better than others, etc). This task is usually quite easily done by humans (Human Resources departments) and relatively well done by computers (keywords).\n",
        "\n",
        "The following cells of this notebook shows a relatively simple model that classifies 'Data Scientists' against 'Human Resources' based on fake resumes (found on google, check disclaimer above). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6i4EvEMYrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_embedding(url):\n",
        "  response = requests.get(url, stream=True)\n",
        "  with open('tmp', 'wb') as file:\n",
        "      shutil.copyfileobj(response.raw, file)\n",
        "  return np.load('tmp', allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuNyJlGEBlel",
        "colab_type": "text"
      },
      "source": [
        "## 2.0. Embeddings Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nYSV4k0zdgi",
        "colab_type": "text"
      },
      "source": [
        "A set of data scientists resumes has been uploaded using client.profile.add_file method. In this section we are retrieving (requires **source_id** and a list of **profile_id**) our uploaded profiles products (parsing and embedding). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGMBp3i-19MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_id = '2be272f86ae21c311a4e0ee9401092026de063fc'\n",
        "data_scientist_ids = ['8f1c04ddb3aa1c00b1b0f406724cf7d260cddaa1', 'b4ec818197ef22f39c9a3761661847981eeb7d43', 'b96a60419769594e6ea4df36cebdb78d3800ce6d', \n",
        "                      '6aabceebb833d97257b6beb1335414536b873651', 'f01119ebe76dd3a979fe309f12d174ee3ec57f84', 'ade02d1f95673a126c96d0553f1daa3ae3c1cacc', \n",
        "                      '81aed5caa0331e96549136ea5cf90fdbf1bef2a5', '59adec3b482f41fdfb8d24a79069decfeb09d191', '2403d2584670a430d14bc45121be6edb9e46c0a6']\n",
        "hr_ids = ['4c2f88ed9ec17859176a9e6bfba765e108e1be9c', 'ea343d3843121bf760ee6afb40c73ce1fae80d21', '7bafcfd41d86814940593ba68658d3782380dc0c',\n",
        "          'fdde179cc1194a1ebdcb250cff590b6426801497', '9659dd9167c50bc401aea57987b65b91a7c2caa3', '9d36930fa252ed53a11a71110bb1998ea73249ba', \n",
        "          '2840d1c78e870d7905cc217945fb9963b703b51b']\n",
        "profiles_ids = data_scientist_ids + hr_ids\n",
        "job_types = ['data_scientist']*len(data_scientist_ids) + ['hr']*len(hr_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6uAjnrKMGqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "job_types_labels = {'data_scientist': 0, 'hr': 1}\n",
        "profiles_embeddings = []\n",
        "labels = []\n",
        "profiles_json = []\n",
        "\n",
        "for job_type, profile_id in tqdm(zip(job_types, profiles_ids)):\n",
        "  # Retrieving Embeddings\n",
        "  response = client.profile.embedding.get(source_id=source_id, profile_id=profile_id, fields={'profile': 1})\n",
        "  profiles_embeddings.append(load_embedding(response['data']['profile']))\n",
        "  labels.append(job_types_labels[job_type])\n",
        "  # Retrieving Parsed Profiles\n",
        "  response = client.profile.parsing.get(source_id=source_id, profile_id=profile_id)\n",
        "  profiles_json.append(response['data'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjbovF8cC_my",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Profile Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aA5R3ElDEic",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.a Model: Shallow Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hcnR8Hp0SQd",
        "colab_type": "text"
      },
      "source": [
        "Our Neural Network is a single (shallow) hidden layer network defined by three layers:\n",
        "*  Input: profiles embeddings lies into $R^{64}$. This explains the input shape 'shape=(64,)'\n",
        "*  Hidden Layer: a simple 64-neurons dense using tanh ($x\\mapsto (e^x-1)/(e^x+1)$) activation function\n",
        "*  Output: probabilities-like real numbers using softmax activation function.\n",
        "\n",
        "Since we are building a classifier we are compiling with the most common loss and optimizer (categorical crossentropy and Adam respectively). More informations about tensorflow neural network library can be found in https://www.tensorflow.org/api_docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbdO0MpQDDGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Model Definition\n",
        "model_input = Input(shape=(64,))\n",
        "dense = Dense(64, activation='tanh')(model_input)\n",
        "softmax = Dense(2, activation='softmax')(dense)\n",
        "model = Model(inputs=[model_input], outputs=[softmax])\n",
        "\n",
        "# Model Compilation (required for training)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZf00SSFDJPh",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.b. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwo25OeF6ThI",
        "colab_type": "text"
      },
      "source": [
        "Remarks on model.fit inputs:\n",
        "*  np.asarray: inputs are feeded as numpy arrays (we retrieved profiles embeddings as python list of arrays)\n",
        "*  to_categorical: the output of the model is a 'list' of (1-p, p) where p is the probability of being part of the second class (label 1). to_categorical turns labels into this shape.\n",
        "*  epochs: can be set to quite any desired value here (since this model does not have any production purpose). 10 epochs (or passes through the data set) proved to be enough for this model to reach good results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n97CmKV7DND5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x=np.asarray(profiles_embeddings), \n",
        "          y=to_categorical(np.asarray(labels)),\n",
        "          epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JesH9mGkDD1u",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.c. Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISlHg-s5kRZU",
        "colab_type": "text"
      },
      "source": [
        "Due to the lack of resumes, the model is evaluated on its training own data (instead of on a validation set). Two evaluation methods are shown:\n",
        "\n",
        "\n",
        "1.   **Confusion Matrix**: a matrix that shows the number of:\n",
        "*   On the **diagonal**: **rightfully predicted** classes\n",
        "*   Anywhere else: wrongly classified resumes\n",
        "\n",
        "\n",
        "2.   **Principal Component Analysis Plot**: uses dimension reduction (projection towards high variance axes) to show high dimensional vectors into a lower dimension (usually 2 or 3). **Decision boundaries** are plotted using the model prediction over a mesh in embedding space. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zX8qMuXDQ1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "# Scatter Plot Hover Text Formating\n",
        "def line_jump(text, every_char=50):\n",
        "    n_jumps = len(text) // every_char\n",
        "    output = text[:every_char]\n",
        "    for index in range(1, n_jumps):\n",
        "        output += '<br />' + text[every_char*index:every_char*(index+1)] \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Imcz3uVDUPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Model's Predictions on Test Set\n",
        "predictions = np.argmax(model.predict(np.asarray(profiles_embeddings)), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27qUcYncDVbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confusion Matrix\n",
        "confusion_matrix = np.asarray(tf.math.confusion_matrix(labels, predictions))\n",
        "text = np.asarray([['Data Scientist detected\\n as Data Scientist', 'Data Scientist wrongly detected\\n as Human Resources'], \n",
        "                   ['Human Resources wrongly detected\\n as Data Scientist', 'Human Resources detected\\n as Human Resources']])\n",
        "text_conf_mat = (np.asarray([\"{1:g}\\n{0}\".format(txt, value) for txt, value in zip(text.flatten(), confusion_matrix.flatten())])).reshape(2,2)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "fig, ax = plt.subplots(figsize=(10,10)) \n",
        "sns.heatmap(confusion_matrix, \n",
        "            linewidths=0.5, cmap=\"YlGnBu\", square=True, \n",
        "            xticklabels=['Data Scientist', 'HR'], yticklabels=['Data Scientist', 'HR'],\n",
        "            annot=text_conf_mat, annot_kws={\"size\": 12}, fmt=\"\")\n",
        "plt.xlabel('Predicted Label', fontsize=15)\n",
        "plt.ylabel('True Label', fontsize=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewc8HrF2DXQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jobs_list = list(job_types_labels.keys())\n",
        "\n",
        "# Principal Component Analysis in Dimension 2\n",
        "pca = PCA(n_components=2).fit(profiles_embeddings)\n",
        "pca_embeddings = pca.transform(profiles_embeddings)\n",
        "\n",
        "# DataFrame\n",
        "df = DataFrame({'Summary': [line_jump(profile['text']['en'][:500], every_char=50) for profile in profiles_json],\n",
        "                'Predicted Category': [jobs_list[pred] for pred in predictions],\n",
        "                'Category': ['Human Resources' if job=='hr' else 'Data Scientist' for job in job_types],\n",
        "                'Classification Success': [jobs_list[pred]==job for pred, job in zip(predictions, job_types)],\n",
        "                'First PCA Axis': pca_embeddings[:, 0], \n",
        "                'Second PCA Axis': pca_embeddings[:, 1]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDYOUAXuBAB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Compute Scores for Mesh Values\n",
        "h = 0.25\n",
        "x_min, x_max = -4, 4\n",
        "y_min, y_max = -4, 4\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "Xmesh = np.c_[xx.ravel(), yy.ravel()]\n",
        "mesh_values = model.predict(pca.inverse_transform(Xmesh))[:,1]\n",
        "\n",
        "# Contour/Boundary Plot\n",
        "data = go.Contour(z=mesh_values,\n",
        "                  x=np.arange(x_min, x_max, h), \n",
        "                  y=np.arange(y_min, y_max, h),\n",
        "                  colorscale=[[0.0, \"rgb(165,0,38)\"],\n",
        "                              [0.1111111111111111, \"rgb(215,48,39)\"],\n",
        "                              [0.2222222222222222, \"rgb(244,109,67)\"],\n",
        "                              [0.3333333333333333, \"rgb(253,174,97)\"],\n",
        "                              [0.4444444444444444, \"rgb(254,224,144)\"],\n",
        "                              [0.5555555555555556, \"rgb(224,243,248)\"],\n",
        "                              [0.6666666666666666, \"rgb(171,217,233)\"],\n",
        "                              [0.7777777777777778, \"rgb(116,173,209)\"],\n",
        "                              [0.8888888888888888, \"rgb(69,117,180)\"],\n",
        "                              [1.0, \"rgb(49,54,149)\"]])\n",
        "layout = {'width': 600, 'height': 600, 'showlegend': False, \n",
        "          'xaxis_title': 'First PCA Axis', \n",
        "          'yaxis_title': 'Second PCA Axis', 'title': 'PCA with Decision Boundaries (HR in red, Data Scientist in Blue)'}\n",
        "fig = go.Figure(data = data, layout=layout)\n",
        "\n",
        "# Profiles Embeddings + PCA 2D\n",
        "scatter = px.scatter(df, x='First PCA Axis', y='Second PCA Axis', \n",
        "                     hover_data=['Summary', 'Predicted Category', 'Category', 'Classification Success'],\n",
        "                     hover_name='Category',\n",
        "                     color='Predicted Category',\n",
        "                     color_discrete_sequence=[\"rgb(165,0,38)\", \"rgb(49,54,149)\"],\n",
        "                     symbol='Classification Success',\n",
        "                     symbol_map={True: \"circle\", False: \"square-open\"})\n",
        "scatter.update_traces(marker=dict(size=10, line=dict(width=1, color=\"rgb(230,230,230)\")))\n",
        "fig.add_trace(scatter.data[0])\n",
        "fig.add_trace(scatter.data[1])\n",
        "\n",
        "# Show Graph\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}